{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wnTMyW41cC1E"
   },
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "cd /root/Development/examples/dreambooth\n",
    "python3 -m venv venv\n",
    "source venv/bin/activate\n",
    "pip install ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "source venv/bin/activate\n",
    "\n",
    "git clone https://github.com/huggingface/diffusers\n",
    "cd diffusers\n",
    "pip install -e .\n",
    "cd ..\n",
    "\n",
    "pip install -r requirements.txt\n",
    "\n",
    "pip install safetensors\n",
    "pip install torch-tb-profiler\n",
    "pip install compel\n",
    "\n",
    "git lfs install\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from accelerate.utils import write_basic_config\n",
    "\n",
    "write_basic_config()  # Write a config file\n",
    "os._exit(00)  # Restart the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# python3 -c \"from accelerate.utils import write_basic_config; write_basic_config()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# accelerate config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!accelerate env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!accelerate test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## base models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# !git clone https://huggingface.co/CompVis/stable-diffusion-v1-4 training_models/stable-diffusion-v1-4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://huggingface.co/runwayml/stable-diffusion-v1-55588 training_models/stable-diffusion-v1-555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://huggingface.co/stabilityai/stable-diffusion-2-1-base training_models/stable-diffusion-2-1-base"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/djbielejeski/Stable-Diffusion-Regularization-Images-person_ddim training_images/Stable-Diffusion-Regularization-Images-person_ddim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/djbielejeski/Stable-Diffusion-Regularization-Images-man_1_ddim_step training_images/Stable-Diffusion-Regularization-Images-man_1_ddim_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/djbielejeski/Stable-Diffusion-Regularization-Images-man_euler training_images/Stable-Diffusion-Regularization-Images-man_euler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/djbielejeski/Stable-Diffusion-Regularization-Images-person-photographs training_images/Stable-Diffusion-Regularization-Images-person-photographs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "local_dir = \"./dog\"\n",
    "snapshot_download(\n",
    "    \"diffusers/dog-example\",\n",
    "    local_dir=local_dir,\n",
    "    repo_type=\"dataset\",\n",
    "    ignore_patterns=\".gitattributes\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!accelerate env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_NAME = \"CompVis/stable-diffusion-v1-4\"\n",
    "# MODEL_NAME = \"runwayml/stable-diffusion-v1-5\"\n",
    "# MODEL_NAME = \"stabilityai/stable-diffusion-2-1-base\"\n",
    "# MODEL_NAME = \"stabilityai/stable-diffusion-2-1\"\n",
    "# MODEL_NAME = \"BAAI/AltDiffusion-m9\"\n",
    "# MODEL_NAME = \"BAAI/AltDiffusion\"\n",
    "\n",
    "# MODEL_NAME = \"stable-diffusion-v1-5\"\n",
    "MODEL_NAME = \"stable-diffusion-2-1-base\"\n",
    "MODEL_PATH = f\"training_models/{MODEL_NAME}\"\n",
    "\n",
    "# INSTANCE_NAME = \"dog\"\n",
    "# INSTANCE_NAME = \"rabbit_toy\"\n",
    "# INSTANCE_NAME = \"gabrieltorcat\"\n",
    "# INSTANCE_NAME = \"gabrieltorcat2\"\n",
    "INSTANCE_NAME = \"gabrieltorcat_512\"\n",
    "INSTANCE_DIR = f\"training_images/{INSTANCE_NAME}\"\n",
    "# CLASS_DIR = \"dog\"\n",
    "# CLASS_DIR = \"toy\"\n",
    "CLASS_DIR = \"man\"\n",
    "# CLASS_DIR = \"person\"\n",
    "# CLASS_DIR = \"Stable-Diffusion-Regularization-Images-man_1_ddim_step/man_1_ddim_step\"\n",
    "# CLASS_DIR = \"Stable-Diffusion-Regularization-Images-person_ddim/person_ddim\"\n",
    "CLASS_DIR = f\"regularization_images/{MODEL_NAME}/{CLASS_DIR}\"\n",
    "OUTPUT_DIR = f\"outputs/{MODEL_NAME}/{INSTANCE_NAME}\"\n",
    "\n",
    "# PROMPT_TOKEN = \"sks\"\n",
    "# PROMPT_TOKEN = \"dbDog\"\n",
    "# PROMPT_TOKEN = \"dbRabbit\"\n",
    "PROMPT_TOKEN = \"gabrieltorcat\"\n",
    "# CLASS_TOKEN = \"dog\"\n",
    "# CLASS_TOKEN = \"toy\"\n",
    "CLASS_TOKEN = \"man\"\n",
    "# CLASS_TOKEN = \"person\"\n",
    "INSTANCE_PROMPT = f\"a photo of {PROMPT_TOKEN} {CLASS_TOKEN}\"\n",
    "# VALIDATION_PROMPT = f\"an oil painting of {PROMPT_TOKEN} {CLASS_TOKEN} sitting next to a wooden window reading a book, by Vincent Van Gogh\"\n",
    "VALIDATION_PROMPT = (\n",
    "    # f\"an oil painting of {PROMPT_TOKEN} {CLASS_TOKEN}, by Vincent Van Gogh\"\n",
    "    f\"a photo of {PROMPT_TOKEN} {CLASS_TOKEN} riding a bike in New York city\"\n",
    ")\n",
    "CLASS_PROMPT = f\"a photo of {CLASS_TOKEN}\"\n",
    "\n",
    "RESOLUTION = 512\n",
    "# RESOLUTION = 768\n",
    "TRAIN_BATCH_SIZE = 1\n",
    "# TRAIN_BATCH_SIZE = 2\n",
    "\n",
    "GRADIENT_ACCUMULATION_STEPS = 1\n",
    "# GRADIENT_ACCUMULATION_STEPS = 2\n",
    "\n",
    "# LEARNING_RATE = 5e-6\n",
    "# LEARNING_RATE = 2e-6\n",
    "# LEARNING_RATE = 1e-6\n",
    "# LEARNING_RATE = 9e-7\n",
    "LEARNING_RATE = 8e-7\n",
    "\n",
    "# MAX_TRAIN_STEPS = 400\n",
    "# MAX_TRAIN_STEPS = 800\n",
    "# MAX_TRAIN_STEPS = 1200\n",
    "MAX_TRAIN_STEPS = 1600\n",
    "\n",
    "# NUM_CLASS_IMAGES = 50\n",
    "# NUM_CLASS_IMAGES = 100\n",
    "# NUM_CLASS_IMAGES = 300\n",
    "# NUM_CLASS_IMAGES = 500\n",
    "NUM_CLASS_IMAGES = 1500\n",
    "SAMPLE_BATCH_SIZE = 1\n",
    "# SAMPLE_BATCH_SIZE = 2\n",
    "\n",
    "CHECKPOINTING_STEPS = 200\n",
    "# CHECKPOINTING_STEPS = 300\n",
    "# CHECKPOINTING_STEPS = 400\n",
    "\n",
    "HUB_TOKEN = \"\"\n",
    "\n",
    "# NUM_CPU_THREADS_PER_PROCESS = 16\n",
    "# NUM_CPU_THREADS_PER_PROCESS = 20\n",
    "NUM_CPU_THREADS_PER_PROCESS = 32"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "#####################################################################\n",
    "#####################################################################\n",
    "#####################################################################\n",
    "\n",
    "accelerate launch \\\n",
    "  \n",
    "  --num_cpu_threads_per_process=$NUM_CPU_THREADS_PER_PROCESS \\\n",
    "  \n",
    "  train_dreambooth.py \\\n",
    "  \n",
    "  --pretrained_model_name_or_path=\"$MODEL_PATH\" \\\n",
    "\n",
    "  --train_text_encoder \\\n",
    "\n",
    "# bitsandbytes\n",
    "#   --use_8bit_adam \\\n",
    "#   --gradient_checkpointing \\\n",
    "\n",
    "# xformers\n",
    "#   --enable_xformers_memory_efficient_attention \\\n",
    "#   --set_grads_to_none \\\n",
    "\n",
    "  --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
    "  --class_data_dir=\"$CLASS_DIR\" \\\n",
    "  --output_dir=\"$OUTPUT_DIR\" \\\n",
    "\n",
    "  --class_prompt=\"$CLASS_PROMPT\" \\\n",
    "  --instance_prompt=\"$INSTANCE_PROMPT\" \\\n",
    "  --validation_prompt=\"$VALIDATION_PROMPT\" \\\n",
    "\n",
    "  --resolution=$RESOLUTION \\\n",
    "  --train_batch_size=$TRAIN_BATCH_SIZE \\\n",
    "\n",
    "  --gradient_accumulation_steps=$GRADIENT_ACCUMULATION_STEPS \\\n",
    "  --learning_rate=$LEARNING_RATE \\\n",
    "\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --max_train_steps=$MAX_TRAIN_STEPS \\\n",
    "\n",
    "  --with_prior_preservation \\\n",
    "  --prior_loss_weight=1.0 \\\n",
    "  --num_class_images=$NUM_CLASS_IMAGES \\\n",
    "  --sample_batch_size=$SAMPLE_BATCH_SIZE \\\n",
    "\n",
    "  --checkpointing_steps=$CHECKPOINTING_STEPS \\\n",
    "  # --resume_from_checkpoint=\"checkpoint-1500\" \\\n",
    "  --resume_from_checkpoint=\"latest\" \\\n",
    "\n",
    "  # --push_to_hub \\\n",
    "  # --hub_token=$HUB_TOKEN \\\n",
    "\n",
    "#####################################################################\n",
    "#####################################################################\n",
    "#####################################################################\n",
    "#####################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# %env LD_LIBRARY_PATH=/usr/lib/x86_64_linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# !env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!accelerate launch \\\n",
    "  --num_cpu_threads_per_process=$NUM_CPU_THREADS_PER_PROCESS \\\n",
    "  train_dreambooth.py \\\n",
    "  --pretrained_model_name_or_path=\"$MODEL_PATH\" \\\n",
    "  --train_text_encoder \\\n",
    "  --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
    "  --class_data_dir=\"$CLASS_DIR\" \\\n",
    "  --output_dir=\"$OUTPUT_DIR\" \\\n",
    "  --class_prompt=\"$CLASS_PROMPT\" \\\n",
    "  --instance_prompt=\"$INSTANCE_PROMPT\" \\\n",
    "  --validation_prompt=\"$VALIDATION_PROMPT\" \\\n",
    "  --resolution=$RESOLUTION \\\n",
    "  --train_batch_size=$TRAIN_BATCH_SIZE \\\n",
    "  --gradient_accumulation_steps=$GRADIENT_ACCUMULATION_STEPS \\\n",
    "  --learning_rate=$LEARNING_RATE \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --lr_warmup_steps=0 \\\n",
    "  --max_train_steps=$MAX_TRAIN_STEPS \\\n",
    "  --with_prior_preservation \\\n",
    "  --prior_loss_weight=1.0 \\\n",
    "  --num_class_images=$NUM_CLASS_IMAGES \\\n",
    "  --sample_batch_size=$SAMPLE_BATCH_SIZE \\\n",
    "  --checkpointing_steps=$CHECKPOINTING_STEPS \\\n",
    "  --resume_from_checkpoint=\"latest\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convert to stable diffusion format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!python ../../scripts/convert_diffusers_to_original_stable_diffusion.py \\\n",
    "    --model_path=\"$OUTPUT_DIR\" \\\n",
    "    --checkpoint_path=\"$OUTPUT_DIR/\"$MODEL_NAME\"_\"$PROMPT_TOKEN\"_\"$CLASS_TOKEN\".ckpt\" \\\n",
    "    --half \\\n",
    "    # --use_safetensors \\"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir OUTPUT_DIR + \"/logs/dreambooth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!tensorboard --logdir $OUTPUT_DIR\"/logs/dreambooth\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRA_PROMPT = \", intricate, highly detailed, smooth, sharp focus, detailed clothing, detailed face, hyperrealistic, cinematic lighting, high resolution, photorealistic, masterpiece, 4K, 8K\"\n",
    "EXTRA_PROMPT = \", intricate, highly detailed, smooth, sharp focus, detailed clothing, detailed face, hyperrealistic, high resolution, photorealistic, masterpiece, 4K, 8K\"\n",
    "\n",
    "prompts = [\n",
    "    INSTANCE_PROMPT,\n",
    "    VALIDATION_PROMPT,\n",
    "    f\"oil painting of {PROMPT_TOKEN} {CLASS_TOKEN}\",\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} on top of mount fuji\" + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} (shaking hands)+ with barack obama\" + EXTRA_PROMPT,\n",
    "    f\"({PROMPT_TOKEN} {CLASS_TOKEN})+ close to barack obama\" + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} in front of the eiffel tower\" + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} smiling as an astronaut\" + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} wearing an astronaut suit in space++\" + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} smiling floating++ inside the international space station\" + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} as a cyborg\" + EXTRA_PROMPT,\n",
    "    f\"digital painting of {PROMPT_TOKEN} {CLASS_TOKEN} as a very bearded pirate with a hat, cinematic lighting, artstation, concept art, illustration, artgerm, bouguereau, fantasy, Surrealist\"\n",
    "    + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} as a cyborg, full lenght shot, super hero pose, biomechanical suit, inflateble shapes, wearing epic bionic cyborg implants, biopunk futuristic wardrobe, artstation, concept art, cyberpunk, octane render\"\n",
    "    + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} shaking hands with (emmanuel macron)0.8\" + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} smiling close to (emmanuel macron)0.8\" + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} smiling close to a beautiful (Jennifer Lawrence)++ at a party\" + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} smiling close to a beautiful (Jennifer Lawrence)++ on the red carpet at the oscars\"\n",
    "    + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} in a ramen bowl\" + EXTRA_PROMPT,\n",
    "    f\"oil painting of {PROMPT_TOKEN} {CLASS_TOKEN}, by Picasso\",\n",
    "    f\"oil painting of ({PROMPT_TOKEN} {CLASS_TOKEN})++++, by Van Gogh\",\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} as a character of the movie (the matrix)++ fighting morpheus from the movie (the matrix)++\"\n",
    "    + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} doing a handstand\" + EXTRA_PROMPT,\n",
    "    f\"a plastic toy of {PROMPT_TOKEN} {CLASS_TOKEN}\",\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} as a fighter jet pilot\" + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} as a F22++ pilot\" + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} as a pilot inside the cockpit of an air force fighter jet\" + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} piloting a fighter jet\" + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} piloting an F22++\" + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} smiling close to a young++ beautiful Angelina Jolie\" + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} smiling close to a young++ beautiful Angelina Jolie on the red carpet at the oscars\"\n",
    "    + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} by the ocean\" + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} celebrating and holding the FIFA football world cup surrounded by famous footballers\"\n",
    "    + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} boxing against Mike Tyson, angry, muscular\" + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} with a (face tatoo)+ close to Mike Tyson\" + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} driving formula 1 car, championship\" + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} winning the super bowl\" + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} as mad max from mad max fury road\" + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} sitting close to mahatma gandhi+, (old photo)++\" + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} as the joker from the dark night\" + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} as the terminator\" + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} as a (blue Na'vi)++ from the (movie Avatar)++ (photo realistic)+++, cgi, cinema\"\n",
    "    + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} as a hobbit\" + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} smiling as an olympic athlete\" + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} holding an (olympic gold medal)+ at the podium, celebration, stadium, press\"\n",
    "    + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} as a cowboy\" + EXTRA_PROMPT,\n",
    "    f\"{PROMPT_TOKEN} {CLASS_TOKEN} as a sheriff riding a horse in the (wild west)++, old photo\" + EXTRA_PROMPT,\n",
    "    # \"autumn in paris, ornate, beautiful, atmosphere, vibe, mist, smoke, fire, chimney, rain, wet, pristine, puddles, melting, dripping, snow, creek, lush, ice, bridge, forest, roses, flowers, by stanley artgerm lau, greg rutkowski, thomas kindkade, alphonse mucha, loish, norman rockwell\",\n",
    "    # \"emma watson as nature magic celestial, top down pose, long hair, soft pink and white transparent cloth, space, D&D, shiny background, intricate, elegant, highly detailed, digital painting, artstation, concept art, smooth, sharp focus, illustration, artgerm, bouguereau\",\n",
    "    # \"Emma Watson as a powerful mysterious sorceress, casting lightning magic, detailed clothing, digital painting, hyperrealistic, fantasy, Surrealist, full body, by Stanley Artgerm Lau and Alphonse Mucha, artstation, highly detailed, sharp focus, sci-fi, stunningly beautiful, dystopian, iridescent gold, cinematic lighting, dark\",\n",
    "    # \"full lenght shot, super hero pose, biomechanical suit, inflateble shapes, wearing epic bionic cyborg implants, masterpiece, intricate, biopunk futuristic wardrobe, highly detailed, artstation, concept art, cyberpunk, octane render\",\n",
    "    # \"\",\n",
    "    # \"\",\n",
    "]\n",
    "\n",
    "# NEGATIVE_PROMPT = None\n",
    "NEGATIVE_PROMPT = \"ugly, distorted face, out of frame, extra limbs, disfigured, deformed, body out of frame, bad anatomy, watermark, signature, cut off, low contrast, underexposed, overexposed, bad art, beginner, amateur, blurry, blurred, grainy, draft, tiling, poorly drawn hands, poorly drawn feet, poorly drawn face,\"\n",
    "\n",
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "from diffusers import (\n",
    "    UNet2DConditionModel,\n",
    "    # DiffusionPipeline,\n",
    "    StableDiffusionPipeline,\n",
    "    KDPM2DiscreteScheduler,\n",
    "    DDIMScheduler,\n",
    "    DPMSolverMultistepScheduler,\n",
    "    UniPCMultistepScheduler,\n",
    ")\n",
    "from transformers import CLIPTextModel\n",
    "import torch\n",
    "from compel import Compel\n",
    "from IPython.display import display\n",
    "\n",
    "CHECKPOINTS = [\n",
    "    # 200,\n",
    "    # 400,\n",
    "    # 600,\n",
    "    # 800,\n",
    "    # 1000,\n",
    "    # 1200,\n",
    "    # 1400,\n",
    "    # 1600,\n",
    "    None,\n",
    "]\n",
    "\n",
    "# HEIGHT=384\n",
    "HEIGHT = 512\n",
    "\n",
    "# WIDTH=512\n",
    "WIDTH = 640\n",
    "# WIDTH=768\n",
    "\n",
    "# NUM_INFERENCE_STEPS=20\n",
    "# NUM_INFERENCE_STEPS=40\n",
    "# NUM_INFERENCE_STEPS=60\n",
    "# NUM_INFERENCE_STEPS=70\n",
    "# NUM_INFERENCE_STEPS=80\n",
    "NUM_INFERENCE_STEPS = 100\n",
    "\n",
    "# GUIDANCE_SCALE=7.5\n",
    "GUIDANCE_SCALE = 10\n",
    "# GUIDANCE_SCALE=15\n",
    "\n",
    "# NUM_IMAGES_PER_PROMPT = 1\n",
    "# NUM_IMAGES_PER_PROMPT=2\n",
    "# NUM_IMAGES_PER_PROMPT=3\n",
    "# NUM_IMAGES_PER_PROMPT=4\n",
    "NUM_IMAGES_PER_PROMPT = 6\n",
    "\n",
    "# Load the pipeline with the same arguments (model, revision) that were used for training\n",
    "model_id = MODEL_PATH\n",
    "\n",
    "print(f\"Model = {model_id}\")\n",
    "\n",
    "# loop over checkpoints and final model\n",
    "for checkpoint in CHECKPOINTS:\n",
    "    print(f\"Checkpoint = {checkpoint}\")\n",
    "\n",
    "    # if is checkpoint\n",
    "    if checkpoint:\n",
    "        image_dir = OUTPUT_DIR + \"/test_output_images\" + \"/checkpoint-\" + str(checkpoint)\n",
    "\n",
    "        unet = UNet2DConditionModel.from_pretrained(OUTPUT_DIR + \"/checkpoint-\" + str(checkpoint) + \"/unet\")\n",
    "\n",
    "        text_encoder = CLIPTextModel.from_pretrained(OUTPUT_DIR + \"/checkpoint-\" + str(checkpoint) + \"/text_encoder\")\n",
    "\n",
    "        pipeline = StableDiffusionPipeline.from_pretrained(\n",
    "            model_id, unet=unet, text_encoder=text_encoder, torch_dtype=torch.float32\n",
    "        )\n",
    "\n",
    "    # if is final model\n",
    "    else:\n",
    "        model_id = OUTPUT_DIR\n",
    "\n",
    "        print(f\"Model = {model_id}\")\n",
    "\n",
    "        image_dir = OUTPUT_DIR + \"/test_output_images\"\n",
    "\n",
    "        # pipeline = StableDiffusionPipeline.from_pretrained(model_id)\n",
    "        pipeline = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float32)\n",
    "\n",
    "    pipeline.to(\"cuda\")\n",
    "    # pipeline = pipeline.to(accelerator.device)\n",
    "    # pipeline.set_progress_bar_config(disable=True)\n",
    "\n",
    "    # set scheduler\n",
    "    # pipeline.scheduler = KDPM2DiscreteScheduler.from_config(pipeline.scheduler.config)\n",
    "    # pipeline.scheduler = DDIMScheduler.from_config(pipeline.scheduler.config)\n",
    "    # pipeline.scheduler = DPMSolverMultistepScheduler.from_config(pipeline.scheduler.config, use_karras_sigmas=True)\n",
    "    pipeline.scheduler = UniPCMultistepScheduler.from_config(pipeline.scheduler.config)\n",
    "\n",
    "    # prompt weighting\n",
    "    compel_proc = Compel(tokenizer=pipeline.tokenizer, text_encoder=pipeline.text_encoder)\n",
    "\n",
    "    # create output dir\n",
    "    if image_dir is not None:\n",
    "        os.makedirs(image_dir, exist_ok=True)\n",
    "\n",
    "    # Perform inference, or save, or push to the hub\n",
    "\n",
    "    for prompt in prompts:\n",
    "        print(f\"Prompt = {prompt}\")\n",
    "\n",
    "        # create promp embeding\n",
    "        prompt_embeds = compel_proc(prompt)\n",
    "\n",
    "        images = pipeline(\n",
    "            # prompt,\n",
    "            prompt_embeds=prompt_embeds,\n",
    "            negative_prompt=NEGATIVE_PROMPT,\n",
    "            num_inference_steps=NUM_INFERENCE_STEPS,\n",
    "            guidance_scale=GUIDANCE_SCALE,\n",
    "            height=HEIGHT,\n",
    "            width=WIDTH,\n",
    "            num_images_per_prompt=NUM_IMAGES_PER_PROMPT,\n",
    "        ).images\n",
    "\n",
    "        for img in images:\n",
    "            now = datetime.datetime.isoformat(datetime.datetime.today())\n",
    "\n",
    "            # display(img)\n",
    "\n",
    "            img.save(image_dir + \"/\" + now + \".png\")\n",
    "\n",
    "        # pipeline.save_pretrained(\"dreambooth-pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import DiffusionPipeline\n",
    "\n",
    "pipe = DiffusionPipeline.from_pretrained(\n",
    "    \"runwayml/stable-diffusion-v1-5\",\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
    "image = pipe(prompt).images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Free runtime memory\n",
    "exit()?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ToNG4fd_dTbF"
   },
   "source": [
    "## Gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "WMCqQ5Tcdsm2"
   },
   "outputs": [],
   "source": [
    "# @markdown Run Gradio UI for generating images.\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "def inference(\n",
    "    prompt,\n",
    "    negative_prompt,\n",
    "    num_samples,\n",
    "    height=512,\n",
    "    width=512,\n",
    "    num_inference_steps=50,\n",
    "    guidance_scale=7.5,\n",
    "):\n",
    "    with torch.autocast(\"cuda\"), torch.inference_mode():\n",
    "        return pipe(\n",
    "            prompt,\n",
    "            height=int(height),\n",
    "            width=int(width),\n",
    "            negative_prompt=negative_prompt,\n",
    "            num_images_per_prompt=int(num_samples),\n",
    "            num_inference_steps=int(num_inference_steps),\n",
    "            guidance_scale=guidance_scale,\n",
    "            generator=g_cuda,\n",
    "        ).images\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            prompt = gr.Textbox(label=\"Prompt\", value=\"photo of zwx dog in a bucket\")\n",
    "            negative_prompt = gr.Textbox(label=\"Negative Prompt\", value=\"\")\n",
    "            run = gr.Button(value=\"Generate\")\n",
    "            with gr.Row():\n",
    "                num_samples = gr.Number(label=\"Number of Samples\", value=4)\n",
    "                guidance_scale = gr.Number(label=\"Guidance Scale\", value=7.5)\n",
    "            with gr.Row():\n",
    "                height = gr.Number(label=\"Height\", value=512)\n",
    "                width = gr.Number(label=\"Width\", value=512)\n",
    "            num_inference_steps = gr.Slider(label=\"Steps\", value=24)\n",
    "        with gr.Column():\n",
    "            gallery = gr.Gallery()\n",
    "\n",
    "    run.click(\n",
    "        inference,\n",
    "        inputs=[\n",
    "            prompt,\n",
    "            negative_prompt,\n",
    "            num_samples,\n",
    "            height,\n",
    "            width,\n",
    "            num_inference_steps,\n",
    "            guidance_scale,\n",
    "        ],\n",
    "        outputs=gallery,\n",
    "    )\n",
    "\n",
    "demo.launch(debug=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
